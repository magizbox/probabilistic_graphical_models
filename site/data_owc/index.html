<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="Vu Anh">
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>Optical Word Recognition Dataset - PGM</title>
        <link href="../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../css/font-awesome-4.5.0.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="../css/highlight.css">
        <link href="../components/magiz-c-book/src/book.css" rel="stylesheet">
        <link href="../components/magiz-c-course/src/course.css" rel="stylesheet">
        <link href="../components/magiz-c-video/src/video.css" rel="stylesheet">
        <link href="../components/magiz-c-benchmark/src/benchmark.css" rel="stylesheet">
        <link href="../components/magiz-c-paper/src/paper.css" rel="stylesheet">
        <link href="../components/magiz-doc/style.css" rel="stylesheet">
        <link href="../components/magiz-doc/highlight.css" rel="stylesheet">
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->
	
	<script src="../js/jquery-1.10.2.min.js"></script>
        <script src="../js/bootstrap-3.0.3.min.js"></script>
        <script src="../js/highlight.pack.js"></script>
        <script>
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

            ga('create', 'UA-68978617-1', 'magizbox.com');
            ga('send', 'pageview');
        </script> 
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="..">PGM</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                    <li >
                        <a href="..">Home</a>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Docs <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../foundation_probability/">Foundation: Probability</a>
</li>
                            
<li >
    <a href="../foundation_graph/">Foundation: Graph</a>
</li>
                            
<li >
    <a href="../bayes_network/">Bayesian Network</a>
</li>
                            
<li >
    <a href="../template_models/">Tempalte Models for Bayesian Networks</a>
</li>
                            
<li >
    <a href="../unbbayes/">An Introduction to UnBBayes</a>
</li>
                            
<li >
    <a href="../factor_graph/">Factor Graph</a>
</li>
                        </ul>
                    </li>
                    <li class="dropdown active">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Datasets <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../data_medical_domain/">Medical Domain Data</a>
</li>
                            
<li class="active">
    <a href="./">Optical Word Recognition Dataset</a>
</li>
                        </ul>
                    </li>
                </ul>

            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                        <i class="fa fa-search"></i> Search
                    </a>
                </li>
                    <li >
                        <a rel="next" href="../data_medical_domain/">
                            <i class="fa fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li class="disabled">
                        <a rel="prev" >
                            Next <i class="fa fa-arrow-right"></i>
                        </a>
                    </li>
            </ul>
        </div>
    </div>
</div>

        <div class="container">
                <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="main active"><a href="#optical-word-recognition">Optical Word Recognition</a></li>
            <li><a href="#core-task">Core Task</a></li>
    </ul>
</div></div>
                <div class="col-md-9" role="main">

<h1 id="optical-word-recognition">Optical Word Recognition</h1>
<p>We will be studying the computer vision task of recognizing words from images. The task of recognizing words is usually decomposed to recognition of individual characters from their respective images (optical character recognition, OCR), and hence inferring the word. However character recognition is often a very difficult task, and since each character is predicted independent of its neighbors, its results can often contain combinations of characters that may not be possible in English. In this homework we will augment a simple OCR model with additional factors that capture some intuitions based on character co-occurences and image similarities.</p>
<p><img alt="" src="../images/hw2-model.jpg" /></p>
<p>The undirected graphical model for recognition of a given word is given in the figure above. It consists of two types of variables:</p>
<ul>
<li><strong>Image Variables</strong>: These are observed images that we need to predict the corresponsing character of, and the number of these image variables for a word is the number of characters in the word. The value of these image variables is an observed image, represented by an integer id (less than 1000). For the description of the model, assume the id of the image at position i is represented by img(i).</li>
<li><strong>Character Variables</strong>: These are unobserved variables that represent the character prediction for each of the images, and there is one of these for each of the image variables. For our dataset, the domain of these variables is restricted to the ten most frequent characters in the English language ({e,t,a,o,i,n,s,h,r,d} <sup><a href="https://en.wikipedia.org/wiki/Letter_frequency#Relative_frequencies_of_letters_in_the_English_language">[ciation]</a></sup>), instead of the complete alphabet. For the discussion below, assume the predicted character at position i is represented by char(i).</li>
</ul>
<p>The model for a word w will consist of len(w) observed image ids, and the same number of unobserved character variables. For a given assignment to these character variables, the model score will be specified using three types of factors:</p>
<ul>
<li><strong>OCR Factors, <script type="math/tex"> \psi_{o} </script></strong> : These factors capture the predictions of a character-based OCR system, and hence exist between every image variable and its corresponding character variable. The number of these factors of word w is <em>len(w)</em>. The value of factor between an image variable and the character variable at position i is dependent on <em>img(i)</em> and <em>char(i)</em>, and is stored in <strong>ocr.dat</strong> file described in the data section.</li>
<li><strong>Transition Factors, <script type="math/tex"> \psi_{t} </script></strong> : Since we also want to represent the co-occurence frequencies of the characters in our model, we add these factors between all consecutive character variables. The number of these factors of word <em>w</em> is <em>len(w)-1</em>. The value of factor between two character variables at positions <em>i</em> and <em>i+1</em> is dependent on <em>char(i)</em> and <em>char(i+1)</em>, and is high if <em>char(i+1)</em> is frequently preceded by <em>char(i)</em> in english words. These values are given to you in <strong>trans.dat</strong> file described in the data section.</li>
<li><strong>Skip Factors, <script type="math/tex"> \psi_{s} </script></strong> : Another intuition that we would like to capture in our model is that similar images in a word always represent the same character. Thus our model score should be higher if it predicts the same characters for similar images. These factors exist between every pair of image variables that have the same id, i.e. this factor exist between all <em>i</em>,<em>j</em>, <em>i!=j</em> such that <em>img(i)==img(j)</em>. The value of this factor depends on <em>char(i)</em> and <em>char(j)</em>, and is 5.0 if <em>char(i)==char(j)</em>, and 1.0 otherwise.</li>
</ul>
<p>You can download all the data <a href="https://github.com/magizbox/probabilistic_graphical_models/blob/master/docs/labs/datasets/ocw_dataset.zip">here</a>. The archive contains the following files:</p>
<ul>
<li><strong>ocr.dat</strong>: Contains the output predictions of a pre-existing OCR system for the set of thousand images. Each row contains three tab separated values "id a prob" and represents the OCR system's probability that image id represents character <script type="math/tex"> a </script>, <script type="math/tex"> p(char=a | img=id) = prob </script>. Use these values directly as the value of the factor between image and character variables at position <script type="math/tex">  i </script>, <script type="math/tex"> \psi_o (image(i)=id, char(i)=a) = prob </script>. Since there are 10 characters and 1000 images, the total number of rows in this file is 10,000.</li>
<li><strong>trans.dat</strong>: Stores the factor potentials for the transition factors. Each row contains three tab-separated values "a b value" that represents the value of factor when the previous character is "a" and the next character is "b", i.e. (char(i)=a, char(i+1)=b) = value. The number of rows in the file is 100 (10*10).
data.dat (and truth.dat): Dataset to run your experiments on (see Core Tasks below). The observed dataset (data.dat) consists observed images of one word on each row. The observed images for a word are represented by a sequence of tab-separated integer ids ("id1 id2 id3"). The true word for these observed set of images is stored the respective row in truth.dat, and is simply a string ("eat"). For the core task (3) below, you should iterate through both the files together to ensure you have the true word along with the observed images.</li>
<li>Extra files (<strong>bicounts.dat</strong>, <strong>allwords.dat</strong>, <strong>allimagesX.dat</strong>): These files are not necessary for the core tasks, but may be useful for further fun and your own exploration. allwords.dat and allimagesX.dat are larger versions of data.dat and truth.dat, i.e. they contain all possible words that can be generated from our restricted set of alphabet, and five samples of their observed image sequences (one in each file). You can run inference on these if you like, but is likely to take 15-20 times longer than the small dataset. bicount.dat is in the same format as trans.dat, but instead of storing inexplicable potentials, it stores the joint probability of the co-occurences of the characters.</li>
</ul>
<h2 id="core-task">Core Task</h2>
<p><strong>1.</strong> <strong>Graphical Model</strong>: Implement the graphical model containing the factors above. For any given assignment to the character variables, your model should be able to calculate the model score. Implemention should allow switching between three models:</p>
<ol>
<li>OCR model: only contains the OCR factors</li>
<li>Transition model: contains OCR and Transition factors</li>
<li>Combined model: containing all three types of factors</li>
</ol>
<p><em>Note</em>: To avoid errors arising from numerical issues, we suggest you represent the factors in the log-space and take sums as much as possible, calculating the log of the model score.</p>
<p><strong>2. Exhaustive Inference</strong>: Using the graphical model, write code to perform exhaustive inference, i.e. your code should be able to calculate the probability of any assignment of the character and image variables. To calculate the normalization constant Z for the word w, you will need to go through all possible assignments to the character variables (there will be <script type="math/tex"> 10^{len(w)} </script> of these).</p>
<p><strong>3. Model Accuracy:</strong> Run your model on the data given in the file data.dat. For every word in the dataset, pick the assignment to character variables that has the highest probability according to the model, and treat this as the model prediction for the word. Using the truth given in truth.dat, compare the accuracy of the model predictions using the following three metrics:
1. Character-wise accuracy: Ratio of correctly predicted characters to total number of characters
2. Word-wise accuracy: Ratio of correctly predicted words to total number of words
3. Average Dataset log-likelihood: For each word given in data.dat, calculate the log of the probability of the true word according to the model. Compute the average of this value for the whole dataset.</p>
<p>Compare all of the three models described in (1) using these three metrics. Also give some examples of words that were incorrect by the OCR model but consequently fixed by the Transition model, and examples of words that were incorrect by the OCR, partially corrected by the Transition model, and then completely fixed by the Combined model.</p></div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>var base_url = '..';</script>
        <script data-main="../mkdocs/js/search.js" src="../mkdocs/js/require.js"></script>
        <script src="../js/base.js"></script>
        <script src="../components/underscore/underscore.js"></script>
        <script src="../components/magiz-c-book/src/gspreadsheet.js"></script>
        <script src="../components/magiz-c-paper/src/paper.js"></script>
        <script src="../components/magiz-c-course/src/course.js"></script>
        <script src="../components/magiz-c-benchmark/src/benchmark.js"></script>
        <script src="../components/magiz-c-benchmark/src/bootstrap-popup.js"></script>
        <script src="../components/magiz-c-book/src/book.js"></script>
        <script src="../components/magiz-c-video/src/video.js"></script>
        <script src="../components/jquery/dist/jquery.js"></script>
        <script src="../components/magiz-doc/doc.js"></script>
        <script src="../components/magiz-doc/footer.js"></script>
        <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form role="form">
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
